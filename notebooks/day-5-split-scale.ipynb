{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21f2d9e",
   "metadata": {},
   "source": [
    "---\n",
    "Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680b645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featrure-engineered DataFram 'df_for_modeling' loaded successfully.\n",
      "Sensational!\n",
      "\n",
      "Shape of the loaded DataFrame: (7043, 33)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   SeniorCitizen                          7043 non-null   int64  \n",
      " 1   MonthlyCharges                         7043 non-null   float64\n",
      " 2   TotalCharges                           7043 non-null   float64\n",
      " 3   Churn                                  7043 non-null   int64  \n",
      " 4   HF_neg                                 7043 non-null   float32\n",
      " 5   HF_nue                                 7043 non-null   float32\n",
      " 6   HF_pos                                 7043 non-null   float32\n",
      " 7   gender_Male                            7043 non-null   bool   \n",
      " 8   Partner_Yes                            7043 non-null   bool   \n",
      " 9   Dependents_Yes                         7043 non-null   bool   \n",
      " 10  PhoneService_Yes                       7043 non-null   bool   \n",
      " 11  MultipleLines_Yes                      7043 non-null   bool   \n",
      " 12  InternetService_Fiber optic            7043 non-null   bool   \n",
      " 13  InternetService_No                     7043 non-null   bool   \n",
      " 14  OnlineSecurity_Yes                     7043 non-null   bool   \n",
      " 15  OnlineBackup_Yes                       7043 non-null   bool   \n",
      " 16  DeviceProtection_Yes                   7043 non-null   bool   \n",
      " 17  TechSupport_Yes                        7043 non-null   bool   \n",
      " 18  StreamingTV_Yes                        7043 non-null   bool   \n",
      " 19  StreamingMovies_Yes                    7043 non-null   bool   \n",
      " 20  Contract_One year                      7043 non-null   bool   \n",
      " 21  Contract_Two year                      7043 non-null   bool   \n",
      " 22  PaperlessBilling_Yes                   7043 non-null   bool   \n",
      " 23  PaymentMethod_Credit card (automatic)  7043 non-null   bool   \n",
      " 24  PaymentMethod_Electronic check         7043 non-null   bool   \n",
      " 25  PaymentMethod_Mailed check             7043 non-null   bool   \n",
      " 26  HF_Label_Neutral                       7043 non-null   bool   \n",
      " 27  HF_Label_Positive                      7043 non-null   bool   \n",
      " 28  TenureGrp_13-24 Months                 7043 non-null   bool   \n",
      " 29  TenureGrp_25-36 Months                 7043 non-null   bool   \n",
      " 30  TenureGrp_37-48 Months                 7043 non-null   bool   \n",
      " 31  TenureGrp_49-60 Months                 7043 non-null   bool   \n",
      " 32  TenureGrp_61-72 Months                 7043 non-null   bool   \n",
      "dtypes: bool(26), float32(3), float64(2), int64(2)\n",
      "memory usage: 481.6 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # For joining paths\n",
    "\n",
    "parquet_fe_file_path = r\"C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\telco_churn_feature_engineered.parquet\"\n",
    "try:\n",
    "    df_for_modeling = pd.read_parquet(parquet_fe_file_path)\n",
    "    print(\"Featrure-engineered DataFram 'df_for_modeling' loaded successfully.\\nSensational!\\n\")\n",
    "    print(f\"Shape of the loaded DataFrame: {df_for_modeling.shape}\\n\")\n",
    "    df_for_modeling.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {parquet_fe_file_path}.\\nPlease ensure it was saved correctly, check the path, and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6d333",
   "metadata": {},
   "source": [
    "Dropping columns related to Hugging Face Sentiment analysis because it creates data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14942dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped leaky sentiment features: ['HF_neg', 'HF_nue', 'HF_pos', 'HF_Label_Neutral', 'HF_Label_Positive']\n",
      "Shape of df_for_modeling after dropping: (7043, 28)\n",
      "\n",
      "Info for df_corrected (after dropping leaky features):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   SeniorCitizen                          7043 non-null   int64  \n",
      " 1   MonthlyCharges                         7043 non-null   float64\n",
      " 2   TotalCharges                           7043 non-null   float64\n",
      " 3   Churn                                  7043 non-null   int64  \n",
      " 4   gender_Male                            7043 non-null   bool   \n",
      " 5   Partner_Yes                            7043 non-null   bool   \n",
      " 6   Dependents_Yes                         7043 non-null   bool   \n",
      " 7   PhoneService_Yes                       7043 non-null   bool   \n",
      " 8   MultipleLines_Yes                      7043 non-null   bool   \n",
      " 9   InternetService_Fiber optic            7043 non-null   bool   \n",
      " 10  InternetService_No                     7043 non-null   bool   \n",
      " 11  OnlineSecurity_Yes                     7043 non-null   bool   \n",
      " 12  OnlineBackup_Yes                       7043 non-null   bool   \n",
      " 13  DeviceProtection_Yes                   7043 non-null   bool   \n",
      " 14  TechSupport_Yes                        7043 non-null   bool   \n",
      " 15  StreamingTV_Yes                        7043 non-null   bool   \n",
      " 16  StreamingMovies_Yes                    7043 non-null   bool   \n",
      " 17  Contract_One year                      7043 non-null   bool   \n",
      " 18  Contract_Two year                      7043 non-null   bool   \n",
      " 19  PaperlessBilling_Yes                   7043 non-null   bool   \n",
      " 20  PaymentMethod_Credit card (automatic)  7043 non-null   bool   \n",
      " 21  PaymentMethod_Electronic check         7043 non-null   bool   \n",
      " 22  PaymentMethod_Mailed check             7043 non-null   bool   \n",
      " 23  TenureGrp_13-24 Months                 7043 non-null   bool   \n",
      " 24  TenureGrp_25-36 Months                 7043 non-null   bool   \n",
      " 25  TenureGrp_37-48 Months                 7043 non-null   bool   \n",
      " 26  TenureGrp_49-60 Months                 7043 non-null   bool   \n",
      " 27  TenureGrp_61-72 Months                 7043 non-null   bool   \n",
      "dtypes: bool(24), float64(2), int64(2)\n",
      "memory usage: 385.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop due to data leakage from CustomerReview-derived sentiment. Hugging Face sentiment features.\n",
    "\n",
    "leaky_hf_sentiment_features = [\n",
    "    'HF_neg', 'HF_nue', 'HF_pos',\n",
    "    'HF_Label_Neutral', 'HF_Label_Positive'   # These were created by get_dummies from HF_Label\n",
    "    # The base category (e.g., 'HF_Label_Negative') was dropped by drop_first=True\n",
    "]\n",
    "\n",
    "all_leaky_features_to_drop = leaky_hf_sentiment_features # Using only HF for now as per our findings\n",
    "\n",
    "# Drop only the leaky columns that actually exist in the DataFrame\n",
    "cols_to_drop_leaky = [col for col in all_leaky_features_to_drop if col in df_for_modeling.columns]\n",
    "\n",
    "if cols_to_drop_leaky:\n",
    "    df_for_modeling = df_for_modeling.drop(columns=cols_to_drop_leaky)\n",
    "    print(f\"\\nDropped leaky sentiment features: {cols_to_drop_leaky}\")\n",
    "    print(f\"Shape of df_for_modeling after dropping: {df_corrected.shape}\")\n",
    "else:\n",
    "    print(\"\\nNo specified leaky sentiment features found in df_for_modeling to drop (they might have been dropped already).\")\n",
    "\n",
    "# Verify the columns are gone\n",
    "print(\"\\nInfo for df_corrected (after dropping leaky features):\")\n",
    "df_for_modeling.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41f1087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) and target (y) have been separated.\n",
      "Shape of X: (7043, 27)\n",
      "Shape of y: (7043,)\n",
      "\n",
      "Data successfully split into training and testing sets.\n",
      "Shape of X_train: (5634, 27)\n",
      "Shape of X_test: (1409, 27)\n",
      "Shape of y_train: (5634,)\n",
      "Shape of y_test: (1409,)\n",
      "\n",
      "Churn proportion in y_train:\n",
      "Churn\n",
      "0    0.735\n",
      "1    0.265\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Churn proportion in y_test:\n",
      "Churn\n",
      "0    0.735\n",
      "1    0.265\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "# 1. Separate features (X) and target (y)\n",
    "if 'Churn' in df_for_modeling.columns:\n",
    "    X = df_for_modeling.drop('Churn', axis=1)    # df containing all columns except 'Churn'\n",
    "                                                # all columns are features except 'Churn'\n",
    "    y = df_for_modeling['Churn']                 # series containing target 'Churn'\n",
    "\n",
    "    print(\"Features (X) and target (y) have been separated.\")\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# 2. Split the data into training and testing sets. Used 80/20 split\n",
    "#     and stratify by y to maintain class proportions\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,    # 20% of data will be for testing\n",
    "        random_state=42,  # Ensures reproducibility of the split\n",
    "        stratify=y        # Recommended for classification. Keeps class proportion samples similar in train/test\n",
    "    )\n",
    "\n",
    "    print(\"\\nData successfully split into training and testing sets.\")\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of X_test: {X_test.shape}\")\n",
    "    print(f\"Shape of y_train: {y_train.shape}\")\n",
    "    print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "    # Check the Churn Proportions in y_train and y_test\n",
    "    print(\"\\nChurn proportion in y_train:\")\n",
    "    print(y_train.value_counts(normalize=True).round(3))\n",
    "    print(\"\\nChurn proportion in y_test:\")\n",
    "    print(y_test.value_counts(normalize=True).round(3))\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'Churn' column not found in df_model_ready. Cannot proceed with splitting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe3c0b",
   "metadata": {},
   "source": [
    "---\n",
    "#### Feature Scaling\n",
    "- **Identify Numerical Columns** (aka Numerical Features, Columns with Continuous Data) to Scale\n",
    "- **Choose a Scaler**: StandardScaler from scikit-learn is a common choice. It scales features to have zero mean and unit variance.\n",
    "- **Fit on Training Data ONLY**: This is a critical rule. We calculate the mean and standard deviation (the \"scaling parameters\") only from the X_train data.\n",
    "- **Transform Both Sets**: We then use these parameters learned from X_train to transform both X_train and X_test. This prevents any information from the test set (our \"unseen exam\") from leaking into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3f9743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>TenureGrp_13-24 Months</th>\n",
       "      <th>TenureGrp_25-36 Months</th>\n",
       "      <th>TenureGrp_37-48 Months</th>\n",
       "      <th>TenureGrp_49-60 Months</th>\n",
       "      <th>TenureGrp_61-72 Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  MonthlyCharges  TotalCharges  Churn  gender_Male  \\\n",
       "0              0           29.85         29.85      0        False   \n",
       "1              0           56.95       1889.50      0         True   \n",
       "2              0           53.85        108.15      1         True   \n",
       "3              0           42.30       1840.75      0         True   \n",
       "4              0           70.70        151.65      1        False   \n",
       "\n",
       "   Partner_Yes  Dependents_Yes  PhoneService_Yes  MultipleLines_Yes  \\\n",
       "0         True           False             False              False   \n",
       "1        False           False              True              False   \n",
       "2        False           False              True              False   \n",
       "3        False           False             False              False   \n",
       "4        False           False              True              False   \n",
       "\n",
       "   InternetService_Fiber optic  ...  Contract_Two year  PaperlessBilling_Yes  \\\n",
       "0                        False  ...              False                  True   \n",
       "1                        False  ...              False                 False   \n",
       "2                        False  ...              False                  True   \n",
       "3                        False  ...              False                 False   \n",
       "4                         True  ...              False                  True   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                  False                            True   \n",
       "1                                  False                           False   \n",
       "2                                  False                           False   \n",
       "3                                  False                           False   \n",
       "4                                  False                            True   \n",
       "\n",
       "   PaymentMethod_Mailed check  TenureGrp_13-24 Months  TenureGrp_25-36 Months  \\\n",
       "0                       False                   False                   False   \n",
       "1                        True                   False                    True   \n",
       "2                        True                   False                   False   \n",
       "3                       False                   False                   False   \n",
       "4                       False                   False                   False   \n",
       "\n",
       "   TenureGrp_37-48 Months  TenureGrp_49-60 Months  TenureGrp_61-72 Months  \n",
       "0                   False                   False                   False  \n",
       "1                   False                   False                   False  \n",
       "2                   False                   False                   False  \n",
       "3                    True                   False                   False  \n",
       "4                   False                   False                   False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_modeling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f90f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns identified for scaling: ['MonthlyCharges', 'TotalCharges']\n",
      "Fitting StandardScaler on X_train for columns: ['MonthlyCharges', 'TotalCharges']\n",
      "\n",
      "X_train columns scaled successfully.\n",
      "\n",
      "X_test columns scaled using the scaler fitted on X_train.\n",
      "\n",
      "Scaled numerical features in X_train and X_test have been updated.\n",
      "\n",
      "Head of X_train after scaling (showing scaled columns and a few others):\n",
      "      MonthlyCharges  TotalCharges  gender_Male  Contract_One year\n",
      "3738       -0.521976     -0.263871         True              False\n",
      "3151        0.337478     -0.505423         True              False\n",
      "4860       -0.809013     -0.751850         True              False\n",
      "3867        0.284384     -0.174271        False              False\n",
      "3810       -0.676279     -0.991514         True              False\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns that need scaling\n",
    "# SeniorCitizen is 0/1. Most other columns are one-hot encoded booleans.\n",
    "cols_to_scale = ['MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# Verify columns exist in X_train\n",
    "missing_cols = [col for col in cols_to_scale if col not in X_train.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: The following columns are missing from X_train: {missing_cols}\")\n",
    "else:\n",
    "    print(f\"Columns identified for scaling: {cols_to_scale}\")\n",
    "\n",
    "    \n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data for the specified columns and transform X_train\n",
    "    # IMPORTANT: Fit ONLY on X_train to prevent data leakage from X_test\n",
    "    print(f\"Fitting StandardScaler on X_train for columns: {cols_to_scale}\")\n",
    "    X_train_scaled_cols = scaler.fit_transform(X_train[cols_to_scale])\n",
    "    print(\"\\nX_train columns scaled successfully.\")\n",
    "\n",
    "    # Transform the corresponding columns in X_test using the SAME fitted scaler\n",
    "    X_test_scaled_cols = scaler.transform(X_test[cols_to_scale])\n",
    "    print(\"\\nX_test columns scaled using the scaler fitted on X_train.\")\n",
    "\n",
    "    # Convert the scaled NumPy arrays back to DataFrames with original column names\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled_cols, columns=cols_to_scale, index=X_train.index)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled_cols, columns=cols_to_scale, index=X_test.index)\n",
    "\n",
    "    # Update the original X_train and X_test DataFrames with the scaled columns\n",
    "    # Loop ensures we only update the columns that were scaled\n",
    "    for col in cols_to_scale:\n",
    "        X_train[col] = X_train_scaled_df[col]\n",
    "        X_test[col] = X_test_scaled_df[col]\n",
    "\n",
    "    print(\"\\nScaled numerical features in X_train and X_test have been updated.\")\n",
    "\n",
    "    # Display the head of X_train to see the scaled values for these columns\n",
    "    print(\"\\nHead of X_train after scaling (showing scaled columns and a few others):\")\n",
    "\n",
    "    # Selected columns to display: SCALED ones and a couple of BOOLEAN ones for context.\n",
    "    # [:2] takes first TWO elements from the beginning of the list [up to (but not including) index 2]\n",
    "    display_cols = cols_to_scale + [col for col in X_train.columns if col.startswith('gender_') or col.startswith('Contract_')][:2]\n",
    "\n",
    "    # Ensure display_cols only contains columns that actually exist, in case some boolean ones aren't there\n",
    "    display_cols = [col for col in display_cols if col in X_train.columns]\n",
    "    print(X_train[display_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea00afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled columns in X_train (should be close to 0):\n",
      "MonthlyCharges   -0.0\n",
      "TotalCharges     -0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of scaled columns in X_train (should be close to 1):\n",
      "MonthlyCharges    1.00009\n",
      "TotalCharges      1.00009\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check MEAN and STD of the scaled columns in X_train\n",
    "print(\"Mean of scaled columns in X_train (should be close to 0):\")\n",
    "print(X_train[cols_to_scale].mean().round(5))\n",
    "print(\"\\nStandard deviation of scaled columns in X_train (should be close to 1):\")\n",
    "print(X_train[cols_to_scale].std().round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d838a",
   "metadata": {},
   "source": [
    "---\n",
    "Save X_train, X_test (DataFrames) and y_train, y_test (Series) into separate Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3c519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured directory exists: C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\training_input\n",
      "X_train saved to C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\training_input\\X_train.parquet\n",
      "X_test saved to C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\training_input\\X_test.parquet\n",
      "y_train saved to C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\training_input\\y_train.parquet\n",
      "y_test saved to C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\training_input\\y_test.parquet\n",
      "\n",
      "All split datasets saved successfully as Parquet files in the 'training_input' subfolder!\n"
     ]
    }
   ],
   "source": [
    "import os # Import the os module\n",
    "#  X_train, X_test, y_train, y_test are split datasets\n",
    "\n",
    "# Define the base path components\n",
    "base_project_folder = r\"C:\\Users\\comat\\GitProjects\\customer-churn-ai\" # Raw string is fine here\n",
    "data_subfolder = \"data\"\n",
    "training_input_subfolder_name = \"training_input\"\n",
    "\n",
    "# Construct the path to the 'training_input' directory robustly\n",
    "training_input_path = os.path.join(base_project_folder, data_subfolder, training_input_subfolder_name)\n",
    "\n",
    "# Ensure the target directory exists, create it if it doesn't\n",
    "try:\n",
    "    os.makedirs(training_input_path, exist_ok=True)\n",
    "    print(f\"Ensured directory exists: {training_input_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directory {training_input_path}: {e}\")\n",
    "    raise # Stop if directory can't be made\n",
    "\n",
    "# Define full file paths using os.path.join()\n",
    "x_train_path = os.path.join(training_input_path, \"X_train.parquet\")\n",
    "x_test_path = os.path.join(training_input_path, \"X_test.parquet\")\n",
    "y_train_path = os.path.join(training_input_path, \"y_train.parquet\")\n",
    "y_test_path = os.path.join(training_input_path, \"y_test.parquet\")\n",
    "\n",
    "try:\n",
    "    # Save DataFrames (X_train, X_test)\n",
    "    X_train.to_parquet(x_train_path, index=False)\n",
    "    print(f\"X_train saved to {x_train_path}\")\n",
    "    X_test.to_parquet(x_test_path, index=False)\n",
    "    print(f\"X_test saved to {x_test_path}\")\n",
    "\n",
    "\n",
    "    # Save Series (y_train, y_test) by converting to DataFrame first\n",
    "    y_train.to_frame(name='Churn').to_parquet(y_train_path, index=False)\n",
    "    print(f\"y_train saved to {y_train_path}\")\n",
    "    y_test.to_frame(name='Churn').to_parquet(y_test_path, index=False)\n",
    "    print(f\"y_test saved to {y_test_path}\")\n",
    "    \n",
    "    print(\"\\nAll split datasets saved successfully as Parquet files in the 'training_input' subfolder!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-ai-en2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
