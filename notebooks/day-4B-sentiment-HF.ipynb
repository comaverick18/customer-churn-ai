{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a0ab693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully! Sensational!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # For DataFrame manipulation (assuming df_clean is loaded)\n",
    "import numpy as np # For numerical operations, especially for handling arrays\n",
    "from scipy.special import softmax # For converting logits to probabilities\n",
    "\n",
    "clean_file_path = r\"C:\\Users\\comat\\GitProjects\\customer-churn-ai\\data\\cleaned_telco_churn.csv\"\n",
    "\n",
    "try:\n",
    "    df_hf = pd.read_csv(clean_file_path)\n",
    "    print(\"Data Loaded Successfully! Sensational!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {clean_file_path}. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b409b94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# From Hugging Face transformers library\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoConfig # To access model configuration like label mappings\n",
    "print(\"Necessary libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c4eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for cardiffnlp/twitter-roberta-base-sentiment-latest...\n",
      "Tokenizer loaded successfully.\n",
      "\n",
      "Loading model for cardiffnlp/twitter-roberta-base-sentiment-latest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the model name\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Load the tokenizer\n",
    "print(f\"Loading tokenizer for {MODEL}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "print(\"Tokenizer loaded successfully.\")\n",
    "\n",
    "# Load the model\n",
    "print(f\"\\nLoading model for {MODEL}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1c229f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model configuration loaded (optional).\n",
      "Labels in model config: {0: 'negative', 1: 'neutral', 2: 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# Optional: You can also load the model's configuration if needed to inspect details like label mappings\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "print(\"\\nModel configuration loaded (optional).\")\n",
    "print(f\"Labels in model config: {config.id2label}\") # This will show how the model internally maps numeric IDs to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ef2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'predict_sentiment_advanced' defined.\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_advanced(text):\n",
    "    \"\"\"\n",
    "    Predicts sentiment for a given text using the loaded RoBERTa model,\n",
    "    returning probabilities for all classes and the predicted label.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        # Handle empty strings or non-string inputs if necessary\n",
    "        # Return a default neutral sentiment or NaN values\n",
    "        return {\n",
    "            'HF_neg': 0.0,\n",
    "            'HF_nue': 1.0, # Defaulting to neutral for empty/bad input\n",
    "            'HF_pos': 0.0,\n",
    "            'HF_Label': 'Neutral' # Or perhaps 'Unknown' or np.nan\n",
    "        }\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    # If you have a GPU and set up PyTorch for it, you might move inputs to GPU here:\n",
    "    # encoded_input = {k: v.to(model.device) for k, v in encoded_input.items()}\n",
    "\n",
    "    # Get model output (logits)\n",
    "    output = model(**encoded_input)\n",
    "    logits = output.logits\n",
    "\n",
    "    # Process logits to get probabilities\n",
    "    scores_np = logits.detach().cpu().numpy()[0]  # Get scores for the first (and only) input\n",
    "    probabilities = softmax(scores_np)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_id = np.argmax(probabilities)\n",
    "    \n",
    "    # Map class ID to label string using model's config\n",
    "    predicted_label = model.config.id2label[predicted_class_id] # Or use the 'config' object directly if loaded separately\n",
    "\n",
    "    # Store probabilities for each class (order depends on config.id2label)\n",
    "    # Assuming config.id2label is {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    # You can make this more robust by iterating through config.id2label if order is not guaranteed\n",
    "    # but for this model, it's standard.\n",
    "    prob_negative = probabilities[0]\n",
    "    prob_neutral = probabilities[1]\n",
    "    prob_positive = probabilities[2]\n",
    "\n",
    "    return {\n",
    "        'HF_neg': prob_negative,\n",
    "        'HF_nue': prob_neutral,\n",
    "        'HF_pos': prob_positive,\n",
    "        'HF_Label': predicted_label.capitalize() # Capitalize for consistency e.g. \"Negative\"\n",
    "    }\n",
    "\n",
    "# Example usage (optional - just to test the function with one review):\n",
    "# test_review = \"This is a fantastic service, I am very happy!\"\n",
    "# test_sentiment = predict_sentiment_advanced(test_review)\n",
    "# print(f\"Sentiment for '{test_review}': {test_sentiment}\")\n",
    "\n",
    "# test_review_neg = \"This is a terrible service, I am very unhappy!\"\n",
    "# test_sentiment_neg = predict_sentiment_advanced(test_review_neg)\n",
    "# print(f\"Sentiment for '{test_review_neg}': {test_sentiment_neg}\")\n",
    "\n",
    "print(\"Function 'predict_sentiment_advanced' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e14a9",
   "metadata": {},
   "source": [
    "---\n",
    "Test Run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ed432a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for 'This is a fantastic service, I am very happy!': {'HF_neg': np.float32(0.0046059242), 'HF_nue': np.float32(0.0066346405), 'HF_pos': np.float32(0.9887594), 'HF_Label': 'Positive'}\n",
      "Sentiment for 'This is a terrible service, I am very unhappy!': {'HF_neg': np.float32(0.9494115), 'HF_nue': np.float32(0.04334269), 'HF_pos': np.float32(0.0072457953), 'HF_Label': 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage (optional - just to test the function with one review):\n",
    "test_review = \"This is a fantastic service, I am very happy!\"\n",
    "test_sentiment = predict_sentiment_advanced(test_review)\n",
    "print(f\"Sentiment for '{test_review}': {test_sentiment}\")\n",
    "\n",
    "test_review_neg = \"This is a terrible service, I am very unhappy!\"\n",
    "test_sentiment_neg = predict_sentiment_advanced(test_review_neg)\n",
    "print(f\"Sentiment for '{test_review_neg}': {test_sentiment_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d75e1",
   "metadata": {},
   "source": [
    "---\n",
    "Apply Function to entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee6f8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying advanced sentiment analysis to all 7043 reviews... (This may take several minutes)\n",
      "\n",
      "Advanced Hugging Face sentiment scores and labels added to df_hf.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Applying advanced sentiment analysis to all {len(df_hf)} reviews... (This may take several minutes)\")\n",
    "\n",
    "# Apply the function to the 'CustomerReview' column\n",
    "# This will return a Series of dictionaries\n",
    "sentiment_results_series = df_hf['CustomerReview'].apply(predict_sentiment_advanced)\n",
    "\n",
    "# Convert the Series of dictionaries into a DataFrame\n",
    "df_sentiment_advanced = pd.DataFrame(sentiment_results_series.tolist(), index=df_hf.index)\n",
    "\n",
    "# Concatenate the new sentiment columns with the original df_hf\n",
    "df_hf = pd.concat([df_hf, df_sentiment_advanced], axis=1)\n",
    "\n",
    "print(\"\\nAdvanced Hugging Face sentiment scores and labels added to df_hf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f187d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with new sentiment columns (first 5 rows):\n",
      "                                      CustomerReview  HF_Label    HF_neg  \\\n",
      "0  Really happy with my plan... no unexpected fee...  Positive  0.005294   \n",
      "1  Really happy with my plan... phone support was...  Positive  0.004702   \n",
      "2  Unfortunately, my service was... frustrated by...  Negative  0.906199   \n",
      "3  Consistently good signal... data plan is a gre...  Positive  0.004989   \n",
      "4  Not satisfied with the billing... billing erro...  Negative  0.930403   \n",
      "\n",
      "     HF_nue    HF_pos  \n",
      "0  0.021416  0.973291  \n",
      "1  0.012738  0.982560  \n",
      "2  0.086496  0.007306  \n",
      "3  0.034239  0.960772  \n",
      "4  0.060820  0.008777  \n"
     ]
    }
   ],
   "source": [
    "columns_to_show_adv = [\n",
    "    'CustomerReview',\n",
    "    'HF_Label',        # The predicted label from predict_sentiment_advanced\n",
    "    'HF_neg', # The probability for Negative\n",
    "    'HF_nue',  # The probability for Neutral\n",
    "    'HF_pos'  # The probability for Positive\n",
    "]\n",
    "print(\"\\nDataFrame with new sentiment columns (first 5 rows):\")\n",
    "print(df_hf[columns_to_show_adv].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e87b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of Hugging Face Sentiment Labels (adv):\n",
      "HF_Label\n",
      "Positive    5177\n",
      "Negative    1818\n",
      "Neutral       48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of Hugging Face Sentiment as Percentages (adv):\n",
      "HF_Label\n",
      "Positive    73.506\n",
      "Negative    25.813\n",
      "Neutral      0.682\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDistribution of Hugging Face Sentiment Labels (adv):\")\n",
    "print(df_hf[\"HF_Label\"].value_counts())\n",
    "\n",
    "print(\"\\nDistribution of Hugging Face Sentiment as Percentages (adv):\")\n",
    "hf_percents = df_hf[\"HF_Label\"].value_counts(normalize=True) * 100\n",
    "print(hf_percents.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-ai-en2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
