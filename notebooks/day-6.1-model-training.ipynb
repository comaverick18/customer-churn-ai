{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ab8a75",
   "metadata": {},
   "source": [
    "#### Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90875b1f",
   "metadata": {},
   "source": [
    "Import packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9b7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for training\n",
    "import pandas as pd\n",
    "import numpy as np # Good to have for ML tasks\n",
    "import os # Import the os module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score # Use later for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a759e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded successfully. Shape: (5634, 32)\n",
      "X_test loaded successfully. Shape: (1409, 32)\n",
      "\n",
      "y_train loaded successfully. Shape: (5634,)\n",
      "y_test loaded successfully. Shape: (1409,)\n",
      "\n",
      "All datasets loaded and y_train/y_test converted to Series.\n"
     ]
    }
   ],
   "source": [
    "# Define the base path components\n",
    "base_project_folder = r\"C:\\Users\\comat\\GitProjects\\customer-churn-ai\" # Raw string is fine here\n",
    "data_subfolder = \"data\"\n",
    "training_input_subfolder_name = \"training_input\"\n",
    "\n",
    "# Construct the path to the 'training_input' directory robustly\n",
    "training_input_path = os.path.join(base_project_folder, data_subfolder, training_input_subfolder_name)\n",
    "\n",
    "# Define full file paths using os.path.join(). (these should match what you saved them as)\n",
    "x_train_path = os.path.join(training_input_path, \"X_train.parquet\")\n",
    "x_test_path = os.path.join(training_input_path, \"X_test.parquet\")\n",
    "y_train_path = os.path.join(training_input_path, \"y_train.parquet\")\n",
    "y_test_path = os.path.join(training_input_path, \"y_test.parquet\")\n",
    "\n",
    "try:\n",
    "    # Load DataFrames (X_train, X_test)\n",
    "    X_train = pd.read_parquet(x_train_path)\n",
    "    X_test = pd.read_parquet(x_test_path)\n",
    "    print(f\"X_train loaded successfully. Shape: {X_train.shape}\")\n",
    "    print(f\"X_test loaded successfully. Shape: {X_test.shape}\")\n",
    "\n",
    "    # Load y_train and y_test (they were saved as DataFrames with a 'Churn' column)\n",
    "    y_train_df = pd.read_parquet(y_train_path)\n",
    "    y_test_df = pd.read_parquet(y_test_path)\n",
    "\n",
    "    # Convert y_train and y_test back to Pandas Series for scikit-learn\n",
    "    if 'Churn' in y_train_df.columns and 'Churn' in y_test_df.columns:\n",
    "        y_train = y_train_df['Churn']\n",
    "        y_test = y_test_df['Churn']\n",
    "        print(f\"\\ny_train loaded successfully. Shape: {y_train.shape}\")\n",
    "        print(f\"y_test loaded successfully. Shape: {y_test.shape}\")\n",
    "        print(\"\\nAll datasets loaded and y_train/y_test converted to Series.\")\n",
    "    else:\n",
    "        print(\"Error: 'Churn' column not found in loaded y_train_df or y_test_df.\")\n",
    "        # Handle error or stop if target is not loaded correctly\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: One or more Parquet files not found. Please check paths:\")\n",
    "    print(f\"  X_train expected at: {x_train_path}\")\n",
    "    print(f\"  X_test expected at: {x_test_path}\")\n",
    "    print(f\"  y_train expected at: {y_train_path}\")\n",
    "    print(f\"  y_test expected at: {y_test_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d6ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of X_train:\n",
      "   SeniorCitizen  MonthlyCharges  TotalCharges    HF_neg    HF_nue    HF_pos  \\\n",
      "0              0       -0.521976     -0.263871 -0.596856 -0.608280  0.631591   \n",
      "1              0        0.337478     -0.505423 -0.594176  0.155381  0.535430   \n",
      "2              0       -0.809013     -0.751850 -0.578528  2.236056  0.265643   \n",
      "3              0        0.284384     -0.174271 -0.599526 -0.571609  0.629585   \n",
      "4              0       -0.676279     -0.991514 -0.595537 -0.536079  0.621505   \n",
      "\n",
      "   gender_Male  Partner_Yes  Dependents_Yes  PhoneService_Yes  ...  \\\n",
      "0         True        False           False             False  ...   \n",
      "1         True         True            True              True  ...   \n",
      "2         True         True            True             False  ...   \n",
      "3        False         True           False              True  ...   \n",
      "4         True         True            True              True  ...   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                  False                            True   \n",
      "1                                  False                           False   \n",
      "2                                  False                           False   \n",
      "3                                   True                           False   \n",
      "4                                  False                            True   \n",
      "\n",
      "   PaymentMethod_Mailed check  HF_Label_Neutral  HF_Label_Positive  \\\n",
      "0                       False             False               True   \n",
      "1                        True             False               True   \n",
      "2                        True             False               True   \n",
      "3                       False             False               True   \n",
      "4                       False             False               True   \n",
      "\n",
      "   TenureGrp_13-24 Months  TenureGrp_25-36 Months  TenureGrp_37-48 Months  \\\n",
      "0                   False                    True                   False   \n",
      "1                    True                   False                   False   \n",
      "2                    True                   False                   False   \n",
      "3                   False                    True                   False   \n",
      "4                   False                   False                   False   \n",
      "\n",
      "   TenureGrp_49-60 Months  TenureGrp_61-72 Months  \n",
      "0                   False                   False  \n",
      "1                   False                   False  \n",
      "2                   False                   False  \n",
      "3                   False                   False  \n",
      "4                   False                   False  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "Head of y_train:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the head of X_train and first 5 of y_train to verify\n",
    "print(\"\\nHead of X_train:\")\n",
    "print(X_train.head())\n",
    "print(\"\\nHead of y_train:\")\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599d4fb",
   "metadata": {},
   "source": [
    "---\n",
    "Initialize Logistic Regression Model and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2648780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model initialized with solver='liblinear' and max_iter=1000.\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the Logistic Regression Model\n",
    "# Begin with mostly default parameters. `liblinear` solver used for binary classification and small datasets.\n",
    "# `random_state` used for reproducibility of results if solver involves randomness.\n",
    "# `max_iter` set to 1000 to ensure convergence for complex datasets. default is 100.\n",
    "log_reg_model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
    "print(\"Logistic Regression model initialized with solver='liblinear' and max_iter=1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5faca6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Logistic Regression model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# 2. Fit/Train the model using the training data.\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3e47e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quick check: Training Accuracy for Logistic Regression: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# QUICK Check on training accuracy [NOT a substitute for test set evaluation!]\n",
    "# This just tells us how well the model fits the data it learned from.\n",
    "y_train_pred_log_reg = log_reg_model.predict(X_train)\n",
    "train_accuracy_log_reg = accuracy_score(y_train, y_train_pred_log_reg)\n",
    "print(f\"\\nQuick check: Training Accuracy for Logistic Regression: {train_accuracy_log_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383a6bd",
   "metadata": {},
   "source": [
    "#### Insights / Notes:\n",
    "* Training accuracy is 1.0, which means the model learned the data so well that it makes no mistakes. This is not necessarily good.  \n",
    "\n",
    "* **Potential Implications**:\n",
    "    * **Overfitting**:\n",
    "        - *Definition*: when a machine learning model learns the training data too specifically, capturing not only the underlying patterns but also the noise and random fluctuations unique to that particular set of data.\n",
    "        - *Result*: model becomes very good at predicting the data it has already seen but performs poorly when it encouter new, unseen data (which will be X_test). This is an issue because an overfit model has poor generization, which is the goal of a predictive model, and will lead to misleading sense of real-world performance.\n",
    "        * *Analogy*:\n",
    "            * Overfitting is like a student who has memorized the exact answers to every single question in the practice textbook (X_train, y_train), so they can ace any test that uses those exact questions.\n",
    "            * However, if the actual exam (X_test, y_test) has slightly different questions or new scenarios (even if based on the same overall subject), the student who only memorized will struggle because they didn't learn the underlying concepts needed to solve new problems.\n",
    "            * We want a student (model) who learns the concepts well enough to perform well on both practice questions and the real exam.  \n",
    "\n",
    "* **Plan**:\n",
    "    * Test log_reg_model on X_test and y_test data, which it hasn't seen before.\n",
    "    * Train Other Models like Random Forest and an XGBoost model. They may behave differently on the training so I can compare their results. Choose one that generalizes best\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-ai-en2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
